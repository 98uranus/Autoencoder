{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, Input, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "from keras.utils import plot_model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39000, 14)\n"
     ]
    }
   ],
   "source": [
    "# Generate some sample data for the autoencoder\n",
    "# x_train = np.random.rand(1000, 12)\n",
    "# x_test = np.random.rand(100, 12)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "df = pd.read_csv(\"Autoencoder1.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from cmath import pi\n",
    "\n",
    "data = df.drop(['Time'], axis=1)\n",
    "y_true = df['Class']\n",
    "\n",
    "r2d = 180/pi\n",
    "\n",
    "data['P'] = r2d * data['P']\n",
    "data['Q'] = r2d * data['Q']\n",
    "data['R'] = r2d * data['R']\n",
    "data['Phi'] = r2d * data['Phi']\n",
    "data['Theta'] = r2d * data['Theta']\n",
    "data['Psi'] = r2d * data['Psi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data, test_size=0.3, random_state=RANDOM_SEED)\n",
    "X_train = pd.DataFrame(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer for the autoencoder\n",
    "input_layer = Input(shape=(12,))\n",
    "\n",
    "# Define the encoder layers\n",
    "encoded = layers.Dense(8, activation='sigmoid')(input_layer)\n",
    "encoded = layers.Dense(4, activation='relu')(encoded)\n",
    "\n",
    "# Define the decoder layers\n",
    "decoded = layers.Dense(8, activation='relu')(encoded)\n",
    "decoded = layers.Dense(12, activation='tanh')(decoded)\n",
    "\n",
    "# Create the autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Compile the model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Plot the model structure\n",
    "plot_model(autoencoder, to_file='DAGMM.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Train the model\n",
    "history = autoencoder.fit(x_train, x_train, epochs=100, batch_size=32, validation_data=(x_test, x_test))\n",
    "\n",
    "# Plot the model loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Use the trained autoencoder to encode the training data\n",
    "encoded_data = autoencoder.encoder(x_train).numpy()\n",
    "\n",
    "# Fit a Gaussian Mixture Model with 2 components to the encoded training data\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GMM to predict the probability densities for the encoded test data\n",
    "encoded_test_data = autoencoder.encoder(x_test).numpy()\n",
    "scores = gmm.score_samples(encoded_test_data)\n",
    "\n",
    "# Identify anomalies based on the GMM probability densities\n",
    "threshold = np.percentile(scores, 5)\n",
    "anomalies = x_test[scores < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1 score\n",
    "y_true = np.zeros_like(scores)\n",
    "y_true[scores < threshold] = 1\n",
    "y_pred = np.zeros_like(scores)\n",
    "y_pred[scores < threshold] = 1\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}\")\n",
    "\n",
    "# Generate precision-recall curve with F1 score\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, scores)\n",
    "f1_scores = 2 * precision * recall / (precision + recall)\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.plot(recall, f1_scores, label='F1 score')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision/F1 score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate score with threshold graph\n",
    "plt.plot(thresholds, precision[:-1], label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e41bc5f122b048a99c7a6865a6ec8c6796f375702dcb3aa78e2f10af5131441"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
