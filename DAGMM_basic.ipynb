{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers, Model\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers, layers, losses\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import precision_recall_curve, confusion_matrix\n",
    "from keras.utils import plot_model\n",
    "import pandas as pd\n",
    "from keras import Input, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data for the autoencoder\n",
    "x_train = np.random.rand(1000, 12)\n",
    "x_test = np.random.rand(100, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 12\n",
    "latent_dim = 3\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = Sequential([\n",
    "            # layers.GaussianNoise(1),\n",
    "            layers.Dense(8, activation='sigmoid',\n",
    "                        activity_regularizer=regularizers.l2(10e-3)),\n",
    "            layers.Dense(4, activation='relu'),\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(8, activation='relu'),\n",
    "            layers.Dense(input_dim, activation='tanh'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(latent_dim)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpointer = ModelCheckpoint(filepath=\"DAGMM\",\n",
    "                               monitor='val_loss',\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./logs',\n",
    "                          histogram_freq=0,\n",
    "                          write_graph=True,\n",
    "                          write_images=True)\n",
    "\n",
    "batch_size = 4\n",
    "nb_epochs = 5\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                        epochs=nb_epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(x_test, x_test),\n",
    "                        callbacks=[checkpointer, tensorboard]).history\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "plt.plot(range(nb_epochs), history['loss'], label='Training Loss')\n",
    "plt.plot(range(nb_epochs), history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained autoencoder to encode the training data\n",
    "encoded_data = autoencoder.encoder(x_train).numpy()\n",
    "\n",
    "# Fit a Gaussian Mixture Model with 2 components to the encoded training data\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(encoded_data)\n",
    "\n",
    "# Use the GMM to predict the probability densities for the encoded test data\n",
    "encoded_test_data = autoencoder.encoder(x_test).numpy()\n",
    "scores = gmm.score_samples(encoded_test_data)\n",
    "\n",
    "# Identify anomalies based on the GMM probability densities\n",
    "threshold = np.percentile(scores, 5)\n",
    "anomalies = x_test[scores < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1 score\n",
    "y_true = np.zeros_like(scores)\n",
    "y_true[scores < threshold] = 1\n",
    "y_pred = np.zeros_like(scores)\n",
    "y_pred[scores < threshold] = 1\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}\")\n",
    "\n",
    "# Generate precision-recall curve with F1 score\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, scores)\n",
    "f1_scores = 2 * precision * recall / (precision + recall)\n",
    "plt.plot(recall, precision, label='Precision-Recall curve')\n",
    "plt.plot(recall, f1_scores, label='F1 score')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision/F1 score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate score with threshold graph\n",
    "plt.plot(thresholds, precision[:-1], label='Precision')\n",
    "plt.plot(thresholds, recall[:-1], label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbe8294542bfef95dc4c1617ea160a86e04009fef3feaf3f675181605b6be6e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
